# .github/workflows/scrape-alphacard.yml
name: Scrape AlphaCard Printers

on:
  workflow_dispatch: # Manual triggering only
    inputs:
      max_printers:
        description: 'Maximum number of printers to scrape (optional)'
        required: false
        default: '1000'
      delay_seconds:
        description: 'Delay between requests (seconds)'
        required: false
        default: '2'
  push:
    branches: [ main ]
    paths: 
      - 'scraper/**'
      - '.github/workflows/**'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 lxml pandas
    
    - name: Run scraper
      run: |
        cd scraper
        python alphacard_scraper.py
      env:
        PYTHONUNBUFFERED: 1
        MAX_PRINTERS: ${{ github.event.inputs.max_printers }}
        SCRAPER_DELAY: ${{ github.event.inputs.delay_seconds }}
    
    - name: Check results and display summary
      run: |
        cd scraper
        if [ -f "alphacard_printers.csv" ]; then
          echo "âœ… CSV file created successfully"
          echo "ðŸ“Š Number of lines: $(wc -l < alphacard_printers.csv)"
          echo "ðŸ“„ File size: $(ls -lh alphacard_printers.csv | awk '{print $5}')"
          
          # Show first few lines of CSV
          echo ""
          echo "ðŸ“‹ First 5 lines of CSV:"
          head -5 alphacard_printers.csv
          
          # Show summary if available
          if [ -f "scrape_summary.json" ]; then
            echo ""
            echo "ðŸ“Š Scraping Summary:"
            cat scrape_summary.json | python -m json.tool
          fi
        else
          echo "âŒ CSV file not found"
          ls -la
          exit 1
        fi
    
    - name: Upload results as artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: alphacard-printers-data-${{ github.run_number }}
        path: |
          scraper/alphacard_printers.csv
          scraper/alphacard_printers.json
          scraper/scrape_summary.json
        retention-days: 30
        compression-level: 6
